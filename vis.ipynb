{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import init_dist, load_checkpoint\n",
    "from mmcv.parallel import MMDataParallel, collate, scatter\n",
    "\n",
    "from mmdet.datasets import build_dataloader, build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.core import tensor2imgs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class AttentionVisualizer:\n",
    "    def __init__(self, model, dataset, url2idx):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.url2idx = url2idx\n",
    "\n",
    "        self.url = \"\"\n",
    "        self.cur_url = None\n",
    "        self.pil_img = None\n",
    "        self.tensor_img = None\n",
    "        self.data = None\n",
    "\n",
    "        self.attn_weights = None\n",
    "\n",
    "        self.setup_widgets()\n",
    "    \n",
    "\n",
    "    def setup_widgets(self):\n",
    "        self.sliders = [\n",
    "            widgets.Text(\n",
    "                value='http://images.cocodataset.org/val2017/000000084031.jpg',\n",
    "                placeholder='Type something',\n",
    "                description='URL (ENTER):',\n",
    "                disabled=False,\n",
    "                continuous_update=False,\n",
    "                layout=widgets.Layout(width='100%')\n",
    "            ),\n",
    "            widgets.FloatSlider(min=0, max=0.99,\n",
    "                        step=0.02, description='X coordinate', value=0.72,\n",
    "                        continuous_update=False,\n",
    "                        layout=widgets.Layout(width='50%')\n",
    "                        ),\n",
    "            widgets.FloatSlider(min=0, max=0.99,\n",
    "                        step=0.02, description='Y coordinate', value=0.40,\n",
    "                        continuous_update=False,\n",
    "                        layout=widgets.Layout(width='50%')),\n",
    "            widgets.Checkbox(\n",
    "              value=True,\n",
    "              description='Direction of self attention',\n",
    "              disabled=False,\n",
    "              indent=False,\n",
    "              layout=widgets.Layout(width='50%'),\n",
    "          ),\n",
    "            widgets.Checkbox(\n",
    "              value=True,\n",
    "              description='Show red dot in attention',\n",
    "              disabled=False,\n",
    "              indent=False,\n",
    "              layout=widgets.Layout(width='50%'),\n",
    "          ),\n",
    "            widgets.Button(\n",
    "                description='save',\n",
    "                disabled=False,\n",
    "                button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "                tooltip='save',\n",
    "                icon='check')\n",
    "        ]\n",
    "        self.o = widgets.Output()\n",
    "\n",
    "    def compute_features(self, data):\n",
    "        model = self.model\n",
    "        hidden_outputs = {}\n",
    "        def attn_mask_hook(name):\n",
    "            def hook(self, input, output):\n",
    "                x = input[0]\n",
    "                # Assume `reduction = 1`, then `inter_channels = C`\n",
    "                # or `inter_channels = C` when `mode=\"gaussian\"`\n",
    "\n",
    "                # NonLocal1d x: [N, C, H]\n",
    "                # NonLocal2d x: [N, C, H, W]\n",
    "                # NonLocal3d x: [N, C, T, H, W]\n",
    "                n = x.size(0)\n",
    "\n",
    "                # NonLocal1d g_x: [N, H, C]\n",
    "                # NonLocal2d g_x: [N, HxW, C]\n",
    "                # NonLocal3d g_x: [N, TxHxW, C]\n",
    "                g_x = self.g(x).view(n, self.inter_channels, -1)\n",
    "                g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "                # NonLocal1d theta_x: [N, H, C], phi_x: [N, C, H]\n",
    "                # NonLocal2d theta_x: [N, HxW, C], phi_x: [N, C, HxW]\n",
    "                # NonLocal3d theta_x: [N, TxHxW, C], phi_x: [N, C, TxHxW]\n",
    "                if self.mode == 'gaussian':\n",
    "                    theta_x = x.view(n, self.in_channels, -1)\n",
    "                    theta_x = theta_x.permute(0, 2, 1)\n",
    "                    if self.sub_sample:\n",
    "                        phi_x = self.phi(x).view(n, self.in_channels, -1)\n",
    "                    else:\n",
    "                        phi_x = x.view(n, self.in_channels, -1)\n",
    "                elif self.mode == 'concatenation':\n",
    "                    theta_x = self.theta(x).view(n, self.inter_channels, -1, 1)\n",
    "                    phi_x = self.phi(x).view(n, self.inter_channels, 1, -1)\n",
    "                else:\n",
    "                    theta_x = self.theta(x).view(n, self.inter_channels, -1)\n",
    "                    theta_x = theta_x.permute(0, 2, 1)\n",
    "                    phi_x = self.phi(x).view(n, self.inter_channels, -1)\n",
    "\n",
    "                pairwise_func = getattr(self, self.mode)\n",
    "                # NonLocal1d pairwise_weight: [N, H, H]\n",
    "                # NonLocal2d pairwise_weight: [N, HxW, HxW]\n",
    "                # NonLocal3d pairwise_weight: [N, TxHxW, TxHxW]\n",
    "                pairwise_weight = pairwise_func(theta_x, phi_x)\n",
    "                \n",
    "                hidden_outputs[name] = pairwise_weight.view(n, x.size(2), x.size(3), x.size(2), x.size(3))\n",
    "\n",
    "            return hook\n",
    "\n",
    "\n",
    "        hooks = []\n",
    "        for module_name, module in model.module.named_modules():\n",
    "            if 'NonLocal' in str(module.__class__):\n",
    "                module.register_forward_hook(attn_mask_hook(module_name))\n",
    "                print(f'{module_name} is registered')\n",
    "        # propagate through the model\n",
    "        with torch.no_grad():\n",
    "            model(return_loss=False, rescale=True, **data)\n",
    "\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "\n",
    "        self.attn_weights = list(hidden_outputs.values())[0].detach().cpu().numpy()[0]\n",
    "    \n",
    "    def compute_on_image(self, url):\n",
    "        if url != self.url:\n",
    "            self.url = url\n",
    "            data = self.dataset[self.url2idx[url]]\n",
    "            data = collate([data], samples_per_gpu=1)\n",
    "            device = next(self.model.parameters()).device  # model device\n",
    "            # scatter to specified GPU\n",
    "            data = scatter(data, [device])[0]\n",
    "            self.data = data\n",
    "            self.compute_features(data)\n",
    "    \n",
    "    def update_chart(self, change):\n",
    "        with self.o:\n",
    "            clear_output()\n",
    "\n",
    "            # j and i are the x and y coordinates of where to look at\n",
    "            # sattn_dir is which direction to consider in the self-attention matrix\n",
    "            # sattn_dot displays a red dot or not in the self-attention map\n",
    "            url, j, i, sattn_dir, sattn_dot = [s.value for s in self.sliders[:-1]]\n",
    "\n",
    "            fig, axs = plt.subplots(ncols=2, nrows=1, figsize=(9, 4))\n",
    "            self.compute_on_image(url)\n",
    "            data = self.data\n",
    "            img_tensor = data['img'][0]\n",
    "            img_meta = data['img_metas'][0][0]\n",
    "            img = tensor2imgs(img_tensor, **img_meta['img_norm_cfg'])[0]\n",
    "            h, w, _ = img_meta['img_shape']\n",
    "            img_show = img[:h, :w, :]\n",
    "            img_show = mmcv.bgr2rgb(img_show)\n",
    "            ori_h, ori_w = img_meta['ori_shape'][:-1]\n",
    "            img_show = mmcv.imresize(img_show, (ori_w, ori_h))\n",
    "\n",
    "            # convert reference point to absolute coordinates\n",
    "            j = int(j * w)\n",
    "            i = int(i * h)\n",
    "            \n",
    "             # how much was the original image upsampled before feeding it to the model\n",
    "            scale = ori_h / h\n",
    "\n",
    "            # compute the downsampling factor for the model\n",
    "            # it should be 32 for standard DETR and 16 for DC5\n",
    "            sattn = self.attn_weights\n",
    "            print('sattn shape:', sattn.shape)\n",
    "            fact = 2 ** round(math.log2(w / sattn.shape[-1]))\n",
    "\n",
    "            # round the position at the downsampling factor\n",
    "            x = ((j // fact) + 0.5) * fact\n",
    "            y = ((i // fact) + 0.5) * fact\n",
    "\n",
    "            axs[0].imshow(img_show)\n",
    "            axs[0].axis('off')\n",
    "            axs[0].add_patch(plt.Circle((x * scale, y * scale), fact // 2, color='r'))\n",
    "\n",
    "            idx = (i // fact, j // fact)\n",
    "            \n",
    "            if sattn_dir:\n",
    "                sattn_map = sattn[idx[0], idx[1], ...]\n",
    "            else:\n",
    "                sattn_map = sattn[..., idx[0], idx[1]]\n",
    "            print('sattn_map sum:', sattn_map.sum())\n",
    "            print('sattn map shape:', sattn_map.shape)\n",
    "            attn_map_copy = sattn_map.copy()\n",
    "            sattn_map[attn_map_copy < (np.percentile(attn_map_copy, 80))] = attn_map_copy.min()\n",
    "            # sattn_map[attn_map_copy > (np.percentile(attn_map_copy, 95))] = np.percentile(attn_map_copy, 95)\n",
    "            sattn_map = mmcv.imresize_like(sattn_map, img_show)\n",
    "            axs[1].imshow(sattn_map, cmap='jet', interpolation='bilinear')\n",
    "            # axs[1].imshow(sattn_map, cmap='cividis', interpolation='nearest')\n",
    "            if sattn_dot:\n",
    "                axs[1].add_patch(plt.Circle((x * scale, y * scale), fact // 2, color='r'))\n",
    "            axs[1].axis('off')\n",
    "            axs[1].set_title(f'self-attention{(i, j)}')\n",
    "\n",
    "            plt.show()\n",
    "            fig = plt.gcf()\n",
    "            DPI = fig.get_dpi()\n",
    "            fig.set_size_inches(ori_w/float(DPI), ori_h/float(DPI))\n",
    "            plt.clf()\n",
    "            plt.imshow(img_show)\n",
    "            plt.imshow(sattn_map, cmap='jet', interpolation='bilinear', alpha=0.3)\n",
    "            # axs.add_patch(plt.Circle((x * scale, y * scale), fact // 2, color='r'))\n",
    "            plt.plot([x * scale], [y * scale], marker='s', color='r')\n",
    "            plt.title(img_meta['ori_filename'])\n",
    "            plt.show()\n",
    "            def on_button_clicked(b):\n",
    "                plt.clf()\n",
    "                plt.imshow(img_show)\n",
    "                plt.imshow(sattn_map, cmap='jet', interpolation='bilinear', alpha=0.3)\n",
    "                # axs.add_patch(plt.Circle((x * scale, y * scale), fact // 2, color='r'))\n",
    "                plt.plot([x * scale], [y * scale], marker='s', color='r')\n",
    "                dst_dir = 'nl_vis'\n",
    "                mmcv.mkdir_or_exist(dst_dir)\n",
    "                img_id, ext = osp.splitext(img_meta['ori_filename'])\n",
    "                filename = osp.join(dst_dir, f'{img_id}_{j}-{i}{ext}')\n",
    "                print(f\"saving {filename}\")\n",
    "                plt.savefig(filename)\n",
    "            self.sliders[-1]._click_handlers.callbacks = []\n",
    "            self.sliders[-1].on_click(on_button_clicked)\n",
    "        \n",
    "    def run(self):\n",
    "      for s in self.sliders:\n",
    "          s.observe(self.update_chart, 'value')\n",
    "      self.update_chart(None)\n",
    "      url, x, y, d, sattn_d, clicked = self.sliders\n",
    "      res = widgets.VBox(\n",
    "      [\n",
    "          url,\n",
    "          widgets.HBox([x, y]),\n",
    "          widgets.HBox([d, sattn_d]),\n",
    "          clicked,\n",
    "          self.o\n",
    "      ])\n",
    "      return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'configs/nonlocal/mask_rcnn_r50_fpn_nl_c4.4_1x_coco.py'\n",
    "checkpoint_file = 'checkpoints/mask_rcnn_r50_fpn_nl_c4.4_1x_coco-8cea600c.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.53s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile(config_file)\n",
    "# set cudnn_benchmark\n",
    "if cfg.get('cudnn_benchmark', False):\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "cfg.model.pretrained = None\n",
    "if cfg.model.get('neck'):\n",
    "    if cfg.model.neck.get('rfp_backbone'):\n",
    "        if cfg.model.neck.rfp_backbone.get('pretrained'):\n",
    "            cfg.model.neck.rfp_backbone.pretrained = None\n",
    "cfg.data.test.test_mode = True\n",
    "\n",
    "# init distributed env first, since logger depends on the dist info.\n",
    "distributed = False\n",
    "\n",
    "# build the dataloader\n",
    "# TODO: support multiple images per gpu (only minor changes are needed)\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "url2idx = {}\n",
    "for idx, info in enumerate(dataset.data_infos):\n",
    "    url2idx[info['coco_url']] = idx\n",
    "\n",
    "# build the model and load checkpoint\n",
    "model = build_detector(cfg.model, train_cfg=None, test_cfg=cfg.test_cfg)\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "checkpoint = load_checkpoint(model, checkpoint_file, map_location='cpu')\n",
    "w = AttentionVisualizer(model, dataset, url2idx)\n",
    "w.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-mmlab",
   "language": "python",
   "name": "open-mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
